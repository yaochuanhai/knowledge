import os
import json
from openai import OpenAI
import streamlit as st
from InterviewReport import InterviewReport

# 1. é¡µé¢é…ç½®ä¸ç¯å¢ƒåˆå§‹åŒ–
st.set_page_config(page_title="Java æ¯’èˆŒé¢è¯•å®˜", page_icon="ğŸ¤–")
st.title("ğŸ¤– å°–é…¸åˆ»è–„çš„ Java é¢è¯•å®˜")

# åŠ è½½æœ¬åœ°ç¯å¢ƒå˜é‡ï¼ˆä»…é™æœ¬åœ°å¼€å‘ï¼‰
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# ä¼˜å…ˆè¯»å– Streamlit Secrets
api_key = st.secrets.get("DEEPSEEK_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
base_url = st.secrets.get("DEEPSEEK_BASE_URL") or os.getenv("DEEPSEEK_BASE_URL")

if not api_key:
    st.error("æœªæ‰¾åˆ° API Keyï¼Œè¯·åœ¨ Streamlit Secrets ä¸­é…ç½® DEEPSEEK_API_KEY")
    st.stop()

client = OpenAI(api_key=api_key, base_url=base_url)

# 2. åˆå§‹åŒ– Session State (æ›¿ä»£ history.json)
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè¯´è¯å°–é…¸åˆ»è–„çš„é¢è¯•å®˜ï¼Œä¸“é—¨æŒ‘ Java ç¨‹åºå‘˜çš„åˆºã€‚"}
    ]

# 3. è¾…åŠ©å‡½æ•°
def query_knowledge_base(topic: str):
    try:
        # æ³¨æ„ï¼šç¡®ä¿ knowledge.json å·²ç»ä¸Šä¼ åˆ° GitHub ä»“åº“æ ¹ç›®å½•
        file_path = os.path.join(os.getcwd(), "knowledge.json")
        if not os.path.exists(file_path):
            return "çŸ¥è¯†åº“æ–‡ä»¶ç¼ºå¤±ã€‚"
        with open(file_path, "r", encoding="utf-8") as f:
            kb = json.load(f)
        for key in kb:
            if topic.strip().lower() in key.lower():
                return kb[key]
        return "æœªæ‰¾åˆ°ç›¸å…³æŠ€æœ¯çŸ¥è¯†ã€‚"
    except Exception as e:
        return f"æŸ¥é˜…å¼‚å¸¸: {e}"

def get_final_report(history):
    system_instruction = (
        "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„ JSON ç”Ÿæˆå™¨ã€‚è¯·æ ¹æ®å¯¹è¯æ€»ç»“é¢è¯•æŠ¥å‘Šã€‚"
        "å¿…é¡»è¾“å‡ºä»¥ä¸‹ç»“æ„çš„ JSONï¼Œä¸å¾—åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š\n"
        "{\n"
        '  "candidate_name": "å§“å",\n'
        '  "final_score": 80,\n'
        '  "top_3_weaknesses": ["å¼±ç‚¹1", "å¼±ç‚¹2", "å¼±ç‚¹3"],\n'
        '  "is_hired": true,\n'
        '  "sharp_summary": "åˆ»è–„è¯„è¯­"\n'
        "}"
    )
    messages = history + [{"role": "system", "content": system_instruction}]
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=messages,
        response_format={"type": "json_object"},
        stream=False
    )
    raw_json_str = response.choices[0].message.content
    return InterviewReport.model_validate_json(raw_json_str)

# å‡½æ•°è°ƒç”¨å·¥å…·å®šä¹‰
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_knowledge",
            "description": "å½“ç”¨æˆ·å›ç­”HashMapã€Springç­‰æŠ€æœ¯æ ˆæ—¶ä½¿ç”¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "topic": {"type": "string", "description": "æŠ€æœ¯æ ˆåç§°"}
                },
                "required": ["topic"]
            }
        }
    }
]

# 4. ä¾§è¾¹æ ï¼šåŠŸèƒ½æ§åˆ¶
with st.sidebar:
    st.header("é¢è¯•æ§åˆ¶å°")
    if st.button("ğŸ ç»“æŸé¢è¯•å¹¶ç”ŸæˆæŠ¥å‘Š"):
        if len(st.session_state.messages) < 3:
            st.warning("é¢è¯•è¿˜æ²¡å¼€å§‹å‘¢ï¼Œæ€¥ç€æŠ•èƒå—ï¼Ÿ")
        else:
            with st.spinner("æ­£åœ¨ç”Ÿæˆæ¯’èˆŒæŠ¥å‘Š..."):
                try:
                    report = get_final_report(st.session_state.messages)
                    st.session_state.report = report
                except Exception as e:
                    st.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")

    if "report" in st.session_state:
        st.divider()
        res = st.session_state.report
        if res.is_hired:
            st.success("ç®—ä½ èµ°è¿ï¼Œæ˜å¤©æ¥ä¸Šç­ã€‚")
        else:
            st.error("æœç„¶ä¸å‡ºæ‰€æ–™ï¼Œä½ å¯ä»¥æ»šäº†ã€‚")
        st.json(res.model_dump())

# 5. èŠå¤©ç•Œé¢æ¸²æŸ“
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# 6. ç”¨æˆ·è¾“å…¥å¤„ç†
if prompt := st.chat_input("è¯´ç‚¹ä»€ä¹ˆæ¥å–æ‚¦é¢è¯•å®˜..."):
    # ç«‹å³å±•ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # è°ƒç”¨ AI å›å¤
    with st.chat_message("assistant"):
        with st.spinner("é¢è¯•å®˜æ­£åœ¨é…é…¿æ¯’æ¶²..."):
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=st.session_state.messages,
                tools=tools
            )
            
            msg = response.choices[0].message
            
            # å¤„ç† Tool Calls (Function Calling)
            if msg.tool_calls:
                st.session_state.messages.append(msg)
                for tool_call in msg.tool_calls:
                    func_name = tool_call.function.name
                    args = json.loads(tool_call.function.arguments)
                    
                    if func_name == "get_knowledge":
                        res_content = query_knowledge_base(args.get('topic'))
                        st.session_state.messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": res_content
                        })
                
                # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼Œè·å–æœ€ç»ˆæ–‡å­—å›å¤
                second_response = client.chat.completions.create(
                    model="deepseek-chat",
                    messages=st.session_state.messages
                )
                final_content = second_response.choices[0].message.content
            else:
                final_content = msg.content
            
            st.markdown(final_content)
            st.session_state.messages.append({"role": "assistant", "content": final_content})