import os
import asyncio
import json
from openai import OpenAI
from dotenv import load_dotenv
from InterviewReport import InterviewReport

load_dotenv()

client = OpenAI(api_key = os.getenv("DEEPSEEK_API_KEY"),base_url = os.getenv("DEEPSEEK_BASE_URL"))
history_path = os.path.join(os.getcwd(),"history.json")

def load_history():
    if os.path.exists(history_path):
        with open(history_path,"r",encoding="utf-8") as f:
             json.load(f)
    else:
        return [{"role":"system","content": "ä½ æ˜¯ä¸€ä¸ªè¯´è¯å°–é…¸åˆ»è–„çš„é¢è¯•å®˜ï¼Œä¸“é—¨æŒ‘ Java ç¨‹åºå‘˜çš„åˆºã€‚"}]

def save_history(history):
    with open(history_path,"w",encoding="utf-8") as f:
        json.dump(history,f,ensure_ascii=False,indent=4)



history = load_history()

def query_knowledge_base(topic: str):
    try:
        file_path = os.path.join(os.getcwd(),"knowledge.json")
        with open(file_path,"f",encoding="utf-8") as f:
            kb = json.load(f)
        for key in kb:
            if topic.strip().lower() in key:
                return kb[key]

    except Exception as e:
        return f"æŸ¥é˜…å¼‚å¸¸{e}"

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_knowledge",
            "description": "å½“ç”¨æˆ·å›ç­”HashMapã€Springæ—¶ä½¿ç”¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "topic": {
                        "type": "string", 
                        "description": "æŠ€æœ¯æ ˆ"
                    }
                },
                "required": ["topic"]
            }
        }
    }
]

def get_final_report(history):
    # æ„é€ ä¸€ä¸ªâ€œæ€»ç»“æŒ‡ä»¤â€
    system_instruction = (
        "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„ JSON ç”Ÿæˆå™¨ã€‚è¯·æ ¹æ®å¯¹è¯æ€»ç»“é¢è¯•æŠ¥å‘Šã€‚"
        "å¿…é¡»è¾“å‡ºä»¥ä¸‹ç»“æ„çš„ JSONï¼Œä¸å¾—åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š\n"
        "{\n"
        '  "candidate_name": "å§“å",\n'
        '  "final_score": 80,\n'
        '  "top_3_weaknesses": ["å¼±ç‚¹1", "å¼±ç‚¹2", "å¼±ç‚¹3"],\n'
        '  "is_hired": true,\n'
        '  "sharp_summary": "åˆ»è–„è¯„è¯­"\n'
        "}"
    )
    messages= history + [{"role":"system","content":system_instruction}]
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=messages,
        response_format={"type": "json_object"},
        stream=False
    )
    raw_json_str = response.choices[0].message.content
    report_data = InterviewReport.model_validate_json(raw_json_str)
    return report_data


async def chat_with_tools(user_input):
    history.append({"role":"user","content":user_input})
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=history,
        tools=tools
    )

    msg = response.choices[0].message

    if msg.tool_calls:
        history.append(msg)
        for tool_call in msg.tool_calls:
            func_name = tool_call.function.name
            args = json.loads(tool_call.function.arguments)
            print(f"[ç³»ç»Ÿæ—¥å¿—] ğŸ” AI æ­£åœ¨åå°æŸ¥é˜…ç§˜ç±...")

            if func_name == "get_knowledge":
                res_content = query_knowledge_base(args.get('topic'))
            history.append({"role":"tool","tool_call_id": tool_call.id,"content":res_content})

        second_response = client.chat.completions.create(
        model="deepseek-chat",
        messages=history
        )
        final_msg = second_response.choices[0].message.content
        print(f"ğŸ¤– AI: {final_msg}")
        history.append({"role": "assistant", "content": str(final_msg)})
    else:
        print(f"ğŸ¤– AI: {msg.content}")
        history.append({"role": "assistant", "content": msg.content})



async def main():
        print("ğŸ¤– é¢è¯•å®˜æé†’ (è¾“å…¥ 'finalize' ç»“æŸé¢è¯•)")
        while True:
            query = input("\nğŸ‘¨â€ğŸ’» ä½ : ")
            if query.lower() == 'finalize':
                res = get_final_report(history)
                file_path = os.path.join(os.getcwd(), "report.json")

                with open(file_path,"w",encoding="utf-8") as f:
                    json.dump(res.model_dump(),f,ensure_ascii=False,indent=4)
                if res.is_hired:
                    print("ç®—ä½ èµ°è¿ï¼Œæ˜å¤©æ¥ä¸Šç­ã€‚")
                else:
                    print("æœç„¶ä¸å‡ºæ‰€æ–™ï¼Œä½ å¯ä»¥æ»šäº†ã€‚")
                break
            await chat_with_tools(query)
        

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e :
        print(f"å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")